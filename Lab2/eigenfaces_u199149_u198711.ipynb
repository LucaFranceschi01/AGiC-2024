{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Session 2: Eigenfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors:\n",
    "\n",
    "    - Luca Franceschi (u199149)\n",
    "    - Telmo Linacisoro (u198711)\n",
    "\n",
    "# Eigenfaces and Principal Component Analysis (PCA)\n",
    "In this notebook, we will explore the concept of Eigenfaces, which are eigenvectors used in the computer vision problem of human face recognition. We will see how PCA can be applied to high-dimensional data like images to reduce the dimensionality while preserving as much variability as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some hyperparameters\n",
    "\n",
    "# Width and height of resized images\n",
    "wh = 50\n",
    "\n",
    "# Number of components of PCA \n",
    "num_components = 16\n",
    "\n",
    "# Number of components in the explained variance plot\n",
    "num_components_plot = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(relative_path: str, image_shape: tuple = (50, 50, 3)):\n",
    "    '''\n",
    "    Preprocesses the images, preparing them for PCA.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    relative_path: str\n",
    "        The relative path from cwd (current working directory) to the dataset.\n",
    "    image_shape: tuple(int, int, int), optional\n",
    "        The wanted size of each image and the channels wanted (3 is RGB)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (imgs, flattened_imgs)\n",
    "        imgs: list containing images in np.array type\n",
    "        flattened_imgs: np.array containing the images flattened in row-major order\n",
    "    '''\n",
    "\n",
    "    # Get full path to dataset\n",
    "    folder_path = os.getcwd() + relative_path\n",
    "\n",
    "    # Open file\n",
    "    imgs = []\n",
    "    flattened_imgs = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.png', 'jpg')):\n",
    "            with Image.open(folder_path + '/' + filename) as image:\n",
    "\n",
    "                # Resize and change type to np.array\n",
    "                image = image.resize(image_shape)\n",
    "                image_array = np.array(image)\n",
    "\n",
    "                # Add arrays to lists to return\n",
    "                imgs.append(image_array)\n",
    "                flattened_imgs.append(image_array.flatten())\n",
    "    \n",
    "    return (imgs, np.array(flattened_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, falttened = process_images('/dataset_500', (wh, wh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_processed_images(images: np.array):\n",
    "    '''\n",
    "    Displays the preprocessed images in a grid\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images: np.array\n",
    "        An array of the images in a two-dimensional array type\n",
    "    '''\n",
    "    \n",
    "    grid_size = int(np.ceil(np.sqrt(len(images))))\n",
    "    # If there are too many images, do 5 columns and the rest rows.\n",
    "    # Otherwise display as square\n",
    "    if grid_size > 5:\n",
    "        nrows = int(np.ceil(len(images)/5))\n",
    "        fig, axes = plt.subplots(nrows, 5, figsize=(10, nrows*2))\n",
    "    else:\n",
    "        fig, axes = plt.subplots(grid_size, grid_size, figsize=(grid_size*2, grid_size*2))\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, im in enumerate(images):\n",
    "        axes[i].imshow(im)\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_processed_images(images[0:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(data: np.array, num_components: int = 10):\n",
    "    '''\n",
    "    Performs Principal Component Analysis (PCA) on the given data and returns the eigenvalues, eigenvectors, and projected data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: np.array\n",
    "        Data array that contains flattened images or landmarks\n",
    "    num_components: int, optional\n",
    "        Number of first-selected num_components\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (eigenvalues, eigenvectors, projection)\n",
    "        eigenvalues: np.array of best num_components eigenvalues\n",
    "        eigenvectors: np.array of best num_components eigenvectors\n",
    "        projection: projection of the data onto the eigenspace\n",
    "    '''\n",
    "    \n",
    "    # Normalization\n",
    "    mean = np.mean(data, axis=0)\n",
    "    normalized_data = data - mean\n",
    "\n",
    "    # Covariance matrix\n",
    "    covariance_matrix = np.cov(normalized_data, rowvar=False) # The variables are columns, the observations are rows (default is reversed)\n",
    "\n",
    "    # Compute eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "\n",
    "    # Sort best components (higher eigenvalue means more variance explained in that eigenvector than in others)\n",
    "    idx = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    eigenvectors = eigenvectors[:, idx]\n",
    "\n",
    "    # Take the first num_components from the spectral decomposition\n",
    "    eigenvectors = eigenvectors[:, :num_components]\n",
    "\n",
    "    # Project into the new eigenspace\n",
    "    projected_data = np.dot(normalized_data, eigenvectors)\n",
    "\n",
    "    return eigenvalues, eigenvectors, projected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigval, eigvec, projection = pca(falttened, num_components=num_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_explained_variance(eigenvalues: np.array, num_components: int = 120, type: str = 'all'):\n",
    "    '''\n",
    "    Displays two plots to understand the explained variance, a bar plot and a line plot.\n",
    "    First will normalize the eigenvalues, to know how important is each one, then make the plots\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eigenvalues: np.array\n",
    "        The eigenvalues of the decomposition\n",
    "    num_components: int, optional\n",
    "        The number of components in the plot\n",
    "    type: str, optional\n",
    "        Type of plot. Can have values 'all', 'line' or 'bar'\n",
    "    '''\n",
    "\n",
    "    eigval_sum = sum(eigenvalues)\n",
    "    explained_variance = np.array([val / eigval_sum for val in eigenvalues])\n",
    "    explained_cummulative = np.cumsum(explained_variance)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    if type == 'all':\n",
    "        ax.bar(range(1, num_components + 1), explained_variance[:num_components], alpha=0.5, align='center', label='Individual explained variance')\n",
    "        ax.plot(range(1, num_components + 1), explained_cummulative[:num_components], 'r-', lw=2, label='Cumulative explained variance')\n",
    "        plt.ylim([0, 1])\n",
    "\n",
    "    elif type == 'line':\n",
    "        ax.plot(range(1, num_components + 1), explained_cummulative[:num_components], 'r-', lw=2, label='Cumulative explained variance')\n",
    "        plt.ylim([explained_cummulative[0]-0.1, 1])\n",
    "    \n",
    "    elif type == 'bar':\n",
    "        ax.bar(range(1, num_components + 1), explained_variance[:num_components], alpha=0.5, align='center', label='Individual explained variance')\n",
    "        plt.ylim([0, explained_variance[0]+0.1])\n",
    "\n",
    "    ax.set_ylabel('Explained Variance')\n",
    "    ax.set_xlabel('Components')\n",
    "    ax.set_title('Explained Variance by PCA Components')\n",
    "\n",
    "    ax.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_explained_variance(eigval, num_components=num_components_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_mean_face(data: np.array,\n",
    "                      image_shape: tuple = (50, 50, 3)):\n",
    "    '''\n",
    "    Displays the mean face coming from the input_vector, with the provided image_shape\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: np.array\n",
    "        Data array that contains flattened images or landmarks\n",
    "    image_shape: tuple(int, int, int), optional\n",
    "        The wanted size of each image and the channels wanted (3 is RGB)\n",
    "    '''\n",
    "\n",
    "    mean_image = np.mean(data, axis=0)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(Image.fromarray(np.uint8(mean_image.reshape(image_shape))))\n",
    "    plt.title('Mean Face')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mean_face(falttened, image_shape=(wh, wh, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_eigenfaces(eigenvectors: np.array,\n",
    "                       image_shape: tuple = (50, 50, 3),\n",
    "                       num_components: int = 10):\n",
    "    '''\n",
    "    Displays the eigenfaces \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eigenvectors: np.array\n",
    "        The eigenvectors of the decomposition\n",
    "    image_shape: tuple(int, int, int), optional\n",
    "        The wanted size of each image and the channels wanted (3 is RGB)\n",
    "    num_components: int, optional\n",
    "        The number of components to display\n",
    "    '''\n",
    "\n",
    "    grid_size = int(np.ceil(np.sqrt(num_components)))\n",
    "    if grid_size > 5:\n",
    "        nrows = int(np.ceil(num_components/5))\n",
    "        fig, axes = plt.subplots(nrows, 5, figsize=(10, nrows*2))\n",
    "    else:\n",
    "        fig, axes = plt.subplots(grid_size, grid_size, figsize=(grid_size*2, grid_size*2))\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(num_components):\n",
    "        vec = eigenvectors[:, i]\n",
    "        vec_norm = 255 * (vec - np.min(vec)) / (np.max(vec) - np.min(vec)) # will display in greyscale [0:255]\n",
    "\n",
    "        eigenface = vec_norm.reshape(image_shape)\n",
    "        axes[i].imshow(Image.fromarray(np.uint8(eigenface)), cmap='gray')\n",
    "        axes[i].set_title('Eigenface {:d}'.format(i+1))\n",
    "        \n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_eigenfaces(eigvec, num_components=num_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_modes_of_variation(mean_img: np.array,\n",
    "                               eigenvalues: np.array,\n",
    "                               eigenvectors: np.array,\n",
    "                               comp: int = 4,\n",
    "                               image_shape: tuple = (50, 50, 3),\n",
    "                               std_devs: np.array = np.arange(-3.0, 3.25, 0.25)):\n",
    "    '''\n",
    "    Displays modes of variation of the PCA decomposition\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mean_img: np.array\n",
    "        Mean image of the data\n",
    "    eigenvalues: np.array\n",
    "        The eigenvalues of the decomposition\n",
    "    eigenvectors: np.array\n",
    "        The eigenvectors of the decomposition\n",
    "    comp: int, optional\n",
    "        Component that will vary\n",
    "    image_shape: tuple(int, int, int), optional\n",
    "        The wanted size of each image and the channels wanted (3 is RGB)\n",
    "    std_devs: np.array, optional\n",
    "        Steps in the standard deviation that will vary\n",
    "    '''\n",
    "\n",
    "    grid_size = int(np.ceil(np.sqrt(len(std_devs))))\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(grid_size*2, grid_size*2))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, std in enumerate(std_devs):\n",
    "        variant = eigenvectors[:, comp] * std * np.sqrt(eigenvalues[comp])\n",
    "        image_flat = (mean_img + variant)\n",
    "        image = image_flat.reshape(image_shape)\n",
    "        # image_norm = 255 * (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "        image_norm = np.clip(image, 0, 255)\n",
    "\n",
    "        axes[i].imshow(Image.fromarray(np.uint8(image_norm)), cmap='gray')\n",
    "        axes[i].set_title(f'{std:.2f} STDs')\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_modes_of_variation(np.mean(falttened, axis=0), eigval, eigvec, comp=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_reconstruction_comparison(original_images: np.array,\n",
    "                                      eigenvectors: np.array,\n",
    "                                      data: np.array,\n",
    "                                      mean_img: np.array,\n",
    "                                      image_shape: tuple = (50, 50, 3),\n",
    "                                      num_components: int = 60,\n",
    "                                      selected_img: int = 0):\n",
    "    '''\n",
    "    Displays the reconstruction of the selected original image component by component\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    original_images: np.array\n",
    "        Array of the original preprocessed images\n",
    "    eigenvectors: np.array\n",
    "        The eigenvectors of the decomposition\n",
    "    data: np.array\n",
    "        Data array that contains flattened images or landmarks\n",
    "    mean_img: np.array\n",
    "        Mean image of the data\n",
    "    image_shape: tuple(int, int, int), optional\n",
    "        The wanted size of each image and the channels wanted (3 is RGB)\n",
    "    num_components: int, optional\n",
    "        Number of components that will be used for the reconstruction\n",
    "    selected_img: int, optional\n",
    "        Index of the selected image\n",
    "    '''\n",
    "    original = original_images[selected_img]\n",
    "\n",
    "    grid_size = int(np.ceil(np.sqrt(num_components+1))) # original image goes in idx 0\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(grid_size*2, grid_size*2))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    axes[0].imshow(Image.fromarray(np.uint8(original)))\n",
    "    axes[0].set_title('Original Image')\n",
    "\n",
    "    for i in range(1, num_components+1):\n",
    "        vec = eigenvectors[:, :i] # truncate up to i components\n",
    "        # Project using the first i components\n",
    "        projection = np.dot(data[selected_img] - mean_img, vec)\n",
    "        # Reproject using the first i components\n",
    "        reprojection = np.dot(projection, vec.T) + mean_img\n",
    "\n",
    "        reconstructed_img = reprojection.reshape(image_shape)\n",
    "        axes[i].imshow(Image.fromarray(np.uint8(reconstructed_img)), cmap='gray')\n",
    "        axes[i].set_title('{:d} components'.format(i+1))\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_reconstruction_comparison(images, eigvec, falttened, np.mean(falttened, axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
