{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection and Recognition CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import scipy.io\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import math\n",
    "\n",
    "# mirar diferencias entre estos dos y elegir uno\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lr = 0.001\n",
    "epoch_step = 20\n",
    "batch_size = 32 # o 16\n",
    "images_path = 'TRAINING/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name, label = self.data[idx]\n",
    "        with Image.open(images_path + image_name) as image:\n",
    "            # Apply transformations if specified\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(labels_path, labels_wanted='boundaries', tr_size=0.8, val_size=0.1):\n",
    "    mat = scipy.io.loadmat(labels_path)['AGC_Challenge3_TRAINING'][0]\n",
    "    data = []\n",
    "    for entry in mat:\n",
    "        key = entry[1][0]\n",
    "        if (labels_wanted == 'boundaries'):\n",
    "            data.append([key, entry[2]])\n",
    "        elif (labels_wanted == 'identity'):\n",
    "            data.append([key, entry[0][0][0]])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std extracted from the train_dataset part of AGC_Challenge3_TRAINING\n",
    "def compute_mean_std(dataset):\n",
    "    all_pixels = []\n",
    "    for image_path, _ in dataset:\n",
    "        with Image.open(images_path + image_path) as image:\n",
    "            image_array = np.array(image)\n",
    "            all_pixels.append(image_array)\n",
    "\n",
    "    all_images = np.stack(all_pixels, axis=0)\n",
    "\n",
    "    mean = np.mean(all_images, axis=(0, 1, 2)) / 255.0 \n",
    "    std_dev = np.std(all_images, axis=(0, 1, 2)) / 255.0\n",
    "\n",
    "    return mean, std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms son copiados, revisar\n",
    "# calcular valores de mean y std del dataset para cada channel\n",
    "# o las de imagenet\n",
    "# flipping, cambios de colores, grayscale\n",
    "# contraste de saturacion \n",
    "# color spaces\n",
    "################\n",
    "\n",
    "all_data = load_data('AGC_Challenge3_Training.mat')\n",
    "train_data, val_data, test_data = random_split(all_data, [0.8, 0.1, 0.1], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# train_mean, train_std = compute_mean_std(train_data)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=train_mean, std=train_std)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = MyData(train_data, transform)\n",
    "val_dataset = MyData(val_data, transform)\n",
    "test_dataset = MyData(test_data, transform)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionCNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.cnn_layers(data)\n",
    "        # x = self.flatten(x) # !!! antes del linear layer \n",
    "        return x\n",
    "\n",
    "    def fit(self, training_data, loss_fn, optimizer: optim.Optimizer): # cross entropy con softmax + adam\n",
    "        self.train()\n",
    "        for batch_idx, (batch_data, target) in enumerate(training_data):\n",
    "            print()\n",
    "            \n",
    "            optimizer.zero_grad()  # Clear the gradients\n",
    "            output = self.forward(batch_data)\n",
    "            loss = loss_fn(output, target)  # Compute the loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update the model's parameters\n",
    "\n",
    "            if batch_idx % epoch_step == 0:\n",
    "                print(f'Epoch {batch_idx} has loss {loss.item()}')\n",
    "\n",
    "    def evaluate(self, validation_data, loss_fn):\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        for images, labels in validation_data:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            output = self.forward(images)\n",
    "            loss = loss_fn(output, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        average_loss = total_loss / len(validation_data)\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "\n",
    "        return average_loss, accuracy\n",
    "\n",
    "    def predict(self, test_image):\n",
    "        self.eval()\n",
    "        with torch.inference_mode(mode=True):\n",
    "            return self.forward(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection = DetectionCNNModel().to(device)\n",
    "print(detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in detection.parameters())\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop as train and then test\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(detection.parameters(), lr=lr)\n",
    "\n",
    "detection.fit(train_loader, loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(detection, 'detection_model.pth') # not model.state_dict() because we want to store the class also"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecognitionCNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "# 2 linear layers\n",
    "# va a sacar un vector y hacer argmax\n",
    "# multimodal ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecognitionCNNModel().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'recognition_model.pth') # not model.state_dict() because we want to store the class also"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
