{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection and Recognition CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import scipy.io\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.jit\n",
    "\n",
    "# mirar diferencias entre estos dos y elegir uno\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.transforms.functional import get_image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lr = 0.001\n",
    "epoch_step = 1\n",
    "epochs = 11\n",
    "batch_size = 32 # o 16\n",
    "images_path = './TRAINING/'\n",
    "resized = (300, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    # the data is in the form [img_name, boundaries] or [img_name, identity]\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name, label = self.data[idx]\n",
    "        with Image.open(images_path + image_name) as image:\n",
    "            # Apply transformations if specified\n",
    "            image = image.convert('RGB')\n",
    "            w, h = get_image_size(image)\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            image = torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "            label = [label[0]/w*resized[0], label[1]/h*resized[1], label[2]/w*resized[0], label[3]/h*resized[1]]\n",
    "            label = torch.tensor(label, dtype=torch.float32)\n",
    "            label = torch.flatten(label)\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(labels_path, labels_wanted='boundaries'):\n",
    "    mat = scipy.io.loadmat(labels_path)['AGC_Challenge3_TRAINING'][0]\n",
    "    data = []\n",
    "    for entry in mat:\n",
    "        key = entry[1][0]\n",
    "        if (labels_wanted == 'boundaries'):\n",
    "            # label = np.array([0, 0, 0, 0], dtype=np.int32)\n",
    "            if (len(entry[2]) > 0):\n",
    "                label = np.array(entry[2][0], dtype=np.int32)\n",
    "                data.append([key, label])\n",
    "        elif (labels_wanted == 'identity'):\n",
    "            data.append([key, entry[0][0][0]])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std extracted from the train_dataset part of AGC_Challenge3_TRAINING\n",
    "def compute_mean_std(dataset):\n",
    "    all_pixels = []\n",
    "    for image_path, _ in dataset:\n",
    "        with Image.open(images_path + image_path) as image:\n",
    "            image_array = np.array(image)\n",
    "            all_pixels.append(image_array)\n",
    "\n",
    "    all_images = np.stack(all_pixels, axis=0)\n",
    "\n",
    "    mean = np.mean(all_images, axis=(0, 1, 2)) / 255.0\n",
    "    std_dev = np.std(all_images, axis=(0, 1, 2)) / 255.0\n",
    "\n",
    "    return mean, std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['image_A0003.jpg', array([147,  25, 369, 262], dtype=int32)], ['image_A0006.jpg', array([249, 293, 664, 708], dtype=int32)], ['image_A0007.jpg', array([ 93,  38, 226, 171], dtype=int32)], ['image_A0011.jpg', array([ 49, 245, 528, 724], dtype=int32)], ['image_A0014.jpg', array([ 72,  57, 230, 215], dtype=int32)], ['image_A0016.jpg', array([234,  38, 337, 141], dtype=int32)], ['image_A0017.jpg', array([127,  81, 386, 340], dtype=int32)], ['image_A0022.jpg', array([164,  55, 296, 187], dtype=int32)], ['image_A0028.jpg', array([125, 113, 283, 271], dtype=int32)], ['image_A0030.jpg', array([267, 138, 492, 363], dtype=int32)], ['image_A0032.jpg', array([106, 110, 309, 313], dtype=int32)], ['image_A0033.jpg', array([106,  78, 277, 249], dtype=int32)], ['image_A0034.jpg', array([ 62, 121, 296, 355], dtype=int32)], ['image_A0035.jpg', array([175, 101, 348, 274], dtype=int32)], ['image_A0038.jpg', array([155,  61, 282, 188], dtype=int32)], ['image_A0040.jpg', array([270, 107, 392, 229], dtype=int32)], ['image_A0041.jpg', array([215, 128, 372, 328], dtype=int32)], ['image_A0042.jpg', array([ 10, 101, 218, 309], dtype=int32)], ['image_A0045.jpg', array([128, 147, 368, 387], dtype=int32)], ['image_A0046.jpg', array([117, 208, 360, 451], dtype=int32)], ['image_A0047.jpg', array([223,  23, 352, 152], dtype=int32)], ['image_A0051.jpg', array([  9,  56, 137, 184], dtype=int32)], ['image_A0054.jpg', array([172, 102, 331, 261], dtype=int32)], ['image_A0055.jpg', array([172,  55, 300, 183], dtype=int32)], ['image_A0056.jpg', array([255, 187, 533, 507], dtype=int32)], ['image_A0058.jpg', array([ 99,  85, 217, 203], dtype=int32)], ['image_A0060.jpg', array([ 48, 103, 306, 361], dtype=int32)], ['image_A0062.jpg', array([465, 323, 776, 634], dtype=int32)], ['image_A0063.jpg', array([639,  37, 751, 167], dtype=int32)], ['image_A0068.jpg', array([ 76,  42, 197, 163], dtype=int32)], ['image_A0069.jpg', array([103,  93, 297, 287], dtype=int32)], ['image_A0070.jpg', array([149,  91, 280, 222], dtype=int32)], ['image_A0072.jpg', array([382, 171, 507, 296], dtype=int32)], ['image_A0074.jpg', array([173,  66, 330, 223], dtype=int32)], ['image_A0076.jpg', array([176,  82, 298, 204], dtype=int32)], ['image_A0077.jpg', array([ 67,  64, 199, 196], dtype=int32)], ['image_A0078.jpg', array([ 571,  549, 1417, 1395], dtype=int32)], ['image_A0080.jpg', array([147,  58, 258, 169], dtype=int32)], ['image_A0081.jpg', array([141, 133, 345, 337], dtype=int32)], ['image_A0086.jpg', array([114,  67, 328, 308], dtype=int32)], ['image_A0089.jpg', array([111, 127, 277, 293], dtype=int32)], ['image_A0091.jpg', array([183,  61, 416, 294], dtype=int32)], ['image_A0092.jpg', array([1120,  546, 2215, 1641], dtype=int32)], ['image_A0096.jpg', array([119,  58, 243, 182], dtype=int32)], ['image_A0098.jpg', array([235,  90, 397, 252], dtype=int32)], ['image_A0099.jpg', array([695,  79, 865, 249], dtype=int32)], ['image_A0100.jpg', array([179,  92, 458, 371], dtype=int32)], ['image_A0101.jpg', array([180,  96, 345, 261], dtype=int32)], ['image_A0103.jpg', array([ 49,  55, 159, 165], dtype=int32)], ['image_A0105.jpg', array([143, 199, 421, 477], dtype=int32)], ['image_A0107.jpg', array([ 69, 171, 296, 398], dtype=int32)], ['image_A0111.jpg', array([394,  82, 497, 185], dtype=int32)], ['image_A0112.jpg', array([  89,  365,  883, 1159], dtype=int32)], ['image_A0113.jpg', array([  9,  75, 134, 200], dtype=int32)], ['image_A0115.jpg', array([ 37,  53, 159, 175], dtype=int32)], ['image_A0119.jpg', array([ 32,  39, 138, 145], dtype=int32)], ['image_A0120.jpg', array([378, 118, 691, 431], dtype=int32)], ['image_A0121.jpg', array([ 37, 133, 300, 396], dtype=int32)], ['image_A0123.jpg', array([386, 279, 793, 686], dtype=int32)], ['image_A0127.jpg', array([106, 147, 381, 422], dtype=int32)], ['image_A0128.jpg', array([110,  19, 216, 125], dtype=int32)], ['image_A0129.jpg', array([149,  55, 273, 179], dtype=int32)], ['image_A0131.jpg', array([138, 149, 368, 379], dtype=int32)], ['image_A0133.jpg', array([ 62,  50, 177, 165], dtype=int32)], ['image_A0134.jpg', array([279, 228, 708, 657], dtype=int32)], ['image_A0135.jpg', array([ 66,  85, 201, 220], dtype=int32)], ['image_A0136.jpg', array([328, 138, 697, 507], dtype=int32)], ['image_A0140.jpg', array([224, 184, 441, 401], dtype=int32)], ['image_A0143.jpg', array([231, 280, 559, 608], dtype=int32)], ['image_A0144.jpg', array([232,  81, 250,  99], dtype=int32)], ['image_A0145.jpg', array([ 547,  165, 1083,  701], dtype=int32)], ['image_A0146.jpg', array([133, 142, 324, 333], dtype=int32)], ['image_A0147.jpg', array([218, 303, 548, 633], dtype=int32)], ['image_A0148.jpg', array([109, 106, 268, 265], dtype=int32)], ['image_A0149.jpg', array([ 827,  234, 1471,  878], dtype=int32)], ['image_A0150.jpg', array([327, 226, 574, 473], dtype=int32)], ['image_A0151.jpg', array([266, 108, 633, 475], dtype=int32)], ['image_A0152.jpg', array([ 656,  760, 1602, 1706], dtype=int32)], ['image_A0155.jpg', array([154,  96, 340, 282], dtype=int32)], ['image_A0156.jpg', array([ 43,  89, 171, 217], dtype=int32)], ['image_A0157.jpg', array([128,  64, 290, 226], dtype=int32)], ['image_A0159.jpg', array([ 50,  38, 217, 205], dtype=int32)], ['image_A0160.jpg', array([215, 185, 382, 399], dtype=int32)], ['image_A0162.jpg', array([333,  92, 574, 333], dtype=int32)], ['image_A0163.jpg', array([1085,  273, 1590,  778], dtype=int32)], ['image_A0164.jpg', array([200, 146, 537, 483], dtype=int32)], ['image_A0165.jpg', array([ 64, 172, 420, 528], dtype=int32)], ['image_A0166.jpg', array([176, 109, 290, 223], dtype=int32)], ['image_A0170.jpg', array([ 31,  65, 172, 206], dtype=int32)], ['image_A0171.jpg', array([200, 120, 379, 299], dtype=int32)], ['image_A0172.jpg', array([249, 215, 524, 490], dtype=int32)], ['image_A0174.jpg', array([489, 221, 927, 659], dtype=int32)], ['image_A0175.jpg', array([133, 118, 304, 289], dtype=int32)], ['image_A0176.jpg', array([ 31,  70, 194, 233], dtype=int32)], ['image_A0180.jpg', array([ 29,  44, 136, 151], dtype=int32)], ['image_A0182.jpg', array([142,  69, 259, 186], dtype=int32)], ['image_A0184.jpg', array([195, 130, 414, 349], dtype=int32)], ['image_A0186.jpg', array([1145,  486, 1698, 1039], dtype=int32)], ['image_A0187.jpg', array([121, 234, 522, 635], dtype=int32)], ['image_A0190.jpg', array([380,  72, 549, 241], dtype=int32)], ['image_A0193.jpg', array([153,  65, 339, 251], dtype=int32)], ['image_A0194.jpg', array([105,  71, 262, 228], dtype=int32)], ['image_A0195.jpg', array([ 57,  84, 194, 221], dtype=int32)], ['image_A0196.jpg', array([453,  85, 605, 237], dtype=int32)], ['image_A0197.jpg', array([ 60,  58, 162, 169], dtype=int32)], ['image_A0198.jpg', array([640,  32, 711, 110], dtype=int32)], ['image_A0202.jpg', array([249,  28, 459, 238], dtype=int32)], ['image_A0205.jpg', array([158, 223, 469, 534], dtype=int32)], ['image_A0211.jpg', array([250,  44, 466, 260], dtype=int32)], ['image_A0212.jpg', array([210,  39, 393, 222], dtype=int32)], ['image_A0213.jpg', array([ 81,  35, 227, 222], dtype=int32)], ['image_A0214.jpg', array([ 678,  125, 1383,  830], dtype=int32)], ['image_A0216.jpg', array([ 52,  75, 185, 208], dtype=int32)], ['image_A0217.jpg', array([152, 180, 538, 566], dtype=int32)], ['image_A0218.jpg', array([117,  89, 242, 214], dtype=int32)], ['image_A0219.jpg', array([164, 106, 323, 265], dtype=int32)], ['image_A0220.jpg', array([180,  14, 325, 159], dtype=int32)], ['image_A0221.jpg', array([2042,  615, 2765, 1338], dtype=int32)], ['image_A0223.jpg', array([102,  81, 256, 235], dtype=int32)], ['image_A0224.jpg', array([ 296,  480,  916, 1100], dtype=int32)], ['image_A0227.jpg', array([ 61, 108, 194, 241], dtype=int32)], ['image_A0228.jpg', array([ 92,  54, 226, 188], dtype=int32)], ['image_A0229.jpg', array([138,  84, 284, 230], dtype=int32)], ['image_A0230.jpg', array([225,  97, 451, 323], dtype=int32)], ['image_A0232.jpg', array([ 92, 106, 314, 328], dtype=int32)], ['image_A0235.jpg', array([ 90,  39, 200, 149], dtype=int32)], ['image_A0236.jpg', array([370, 132, 652, 414], dtype=int32)], ['image_A0237.jpg', array([183, 178, 553, 548], dtype=int32)], ['image_A0238.jpg', array([ 74, 113, 244, 283], dtype=int32)], ['image_A0239.jpg', array([ 87,  64, 202, 179], dtype=int32)], ['image_A0240.jpg', array([485, 120, 531, 169], dtype=int32)], ['image_A0241.jpg', array([ 38,  13, 199, 174], dtype=int32)], ['image_A0242.jpg', array([148,  65, 292, 209], dtype=int32)], ['image_A0244.jpg', array([ 61,  84, 200, 223], dtype=int32)], ['image_A0247.jpg', array([221, 196, 359, 334], dtype=int32)], ['image_A0249.jpg', array([349, 100, 661, 412], dtype=int32)], ['image_A0250.jpg', array([ 48,  82, 248, 282], dtype=int32)], ['image_A0253.jpg', array([251, 148, 416, 357], dtype=int32)], ['image_A0254.jpg', array([173,  59, 280, 166], dtype=int32)], ['image_A0255.jpg', array([167, 117, 410, 360], dtype=int32)], ['image_A0258.jpg', array([ 59,  38, 162, 141], dtype=int32)], ['image_A0259.jpg', array([277, 340, 736, 891], dtype=int32)], ['image_A0261.jpg', array([126, 333, 606, 813], dtype=int32)], ['image_A0265.jpg', array([135,  88, 364, 317], dtype=int32)], ['image_A0266.jpg', array([186,  81, 368, 263], dtype=int32)], ['image_A0267.jpg', array([168,  81, 362, 275], dtype=int32)], ['image_A0269.jpg', array([109,  57, 221, 169], dtype=int32)], ['image_A0271.jpg', array([198,  45, 448, 295], dtype=int32)], ['image_A0273.jpg', array([221, 124, 417, 320], dtype=int32)], ['image_A0278.jpg', array([200, 188, 364, 352], dtype=int32)], ['image_A0280.jpg', array([1899,  639, 3268, 2008], dtype=int32)], ['image_A0281.jpg', array([210, 143, 351, 298], dtype=int32)], ['image_A0283.jpg', array([373,  85, 485, 206], dtype=int32)], ['image_A0284.jpg', array([346,  86, 463, 203], dtype=int32)], ['image_A0291.jpg', array([165,  91, 375, 301], dtype=int32)], ['image_A0292.jpg', array([183,  17, 334, 168], dtype=int32)], ['image_A0294.jpg', array([340,  42, 518, 248], dtype=int32)], ['image_A0295.jpg', array([201,  62, 304, 165], dtype=int32)], ['image_A0296.jpg', array([253, 334, 737, 818], dtype=int32)], ['image_A0299.jpg', array([71, 61, 99, 93], dtype=int32)], ['image_A0300.jpg', array([189, 138, 531, 480], dtype=int32)], ['image_A0301.jpg', array([180,  97, 484, 401], dtype=int32)], ['image_A0303.jpg', array([172,  35, 292, 155], dtype=int32)], ['image_A0304.jpg', array([113,  74, 299, 260], dtype=int32)], ['image_A0305.jpg', array([78, 44, 95, 58], dtype=int32)], ['image_A0306.jpg', array([ 77,  90, 207, 220], dtype=int32)], ['image_A0310.jpg', array([208,  69, 456, 317], dtype=int32)], ['image_A0312.jpg', array([486, 280, 519, 321], dtype=int32)], ['image_A0316.jpg', array([218, 112, 411, 305], dtype=int32)], ['image_A0317.jpg', array([ 48,  66, 164, 182], dtype=int32)], ['image_A0319.jpg', array([117,  62, 230, 175], dtype=int32)], ['image_A0320.jpg', array([225,  99, 332, 206], dtype=int32)], ['image_A0321.jpg', array([266, 257, 640, 631], dtype=int32)], ['image_A0322.jpg', array([146, 126, 302, 282], dtype=int32)], ['image_A0325.jpg', array([ 71, 100, 236, 265], dtype=int32)], ['image_A0326.jpg', array([306,  96, 695, 485], dtype=int32)], ['image_A0328.jpg', array([ 80, 111, 290, 321], dtype=int32)], ['image_A0331.jpg', array([184, 134, 308, 258], dtype=int32)], ['image_A0332.jpg', array([241,  71, 366, 196], dtype=int32)], ['image_A0333.jpg', array([377, 324, 626, 573], dtype=int32)], ['image_A0335.jpg', array([226, 220, 566, 560], dtype=int32)], ['image_A0336.jpg', array([133, 101, 264, 232], dtype=int32)], ['image_A0337.jpg', array([163, 215, 607, 659], dtype=int32)], ['image_A0338.jpg', array([197,  37, 315, 155], dtype=int32)], ['image_A0339.jpg', array([ 85,  54, 208, 177], dtype=int32)], ['image_A0340.jpg', array([149, 102, 379, 332], dtype=int32)], ['image_A0343.jpg', array([144,  99, 369, 324], dtype=int32)], ['image_A0345.jpg', array([ 46,  45, 163, 162], dtype=int32)], ['image_A0346.jpg', array([ 55,  13, 163, 121], dtype=int32)], ['image_A0349.jpg', array([149, 121, 336, 308], dtype=int32)], ['image_A0351.jpg', array([ 747,  407, 1313,  973], dtype=int32)], ['image_A0357.jpg', array([216,  38, 319, 141], dtype=int32)], ['image_A0358.jpg', array([ 46,  75, 205, 234], dtype=int32)], ['image_A0360.jpg', array([421,  71, 688, 338], dtype=int32)], ['image_A0361.jpg', array([144, 213, 481, 550], dtype=int32)], ['image_A0365.jpg', array([242, 225, 365, 348], dtype=int32)], ['image_A0366.jpg', array([ 61,  64, 236, 239], dtype=int32)], ['image_A0367.jpg', array([120,  97, 278, 255], dtype=int32)], ['image_A0369.jpg', array([ 94,  42, 240, 188], dtype=int32)], ['image_A0372.jpg', array([ 85,  51, 353, 319], dtype=int32)], ['image_A0373.jpg', array([ 87,  53, 203, 169], dtype=int32)], ['image_A0374.jpg', array([ 13,  35, 285, 307], dtype=int32)], ['image_A0375.jpg', array([329,  40, 458, 169], dtype=int32)], ['image_A0376.jpg', array([348,  28, 520, 200], dtype=int32)], ['image_A0378.jpg', array([107,  30, 215, 138], dtype=int32)], ['image_A0379.jpg', array([396, 205, 706, 515], dtype=int32)], ['image_A0381.jpg', array([ 85, 109, 234, 258], dtype=int32)], ['image_A0382.jpg', array([236,  46, 361, 171], dtype=int32)], ['image_A0384.jpg', array([122, 100, 286, 264], dtype=int32)], ['image_A0388.jpg', array([123,  85, 252, 214], dtype=int32)], ['image_A0390.jpg', array([762,  88, 905, 231], dtype=int32)], ['image_A0394.jpg', array([ 98,  74, 261, 237], dtype=int32)], ['image_A0396.jpg', array([116, 166, 389, 439], dtype=int32)], ['image_A0397.jpg', array([260, 129, 462, 331], dtype=int32)], ['image_A0398.jpg', array([ 59,  94, 195, 230], dtype=int32)], ['image_A0399.jpg', array([ 64,  46, 176, 158], dtype=int32)], ['image_A0400.jpg', array([ 98,  59, 211, 172], dtype=int32)], ['image_A0401.jpg', array([ 83, 174, 292, 383], dtype=int32)], ['image_A0402.jpg', array([142,  71, 285, 214], dtype=int32)], ['image_A0404.jpg', array([159,  74, 416, 331], dtype=int32)], ['image_A0408.jpg', array([ 44,  39, 152, 147], dtype=int32)], ['image_A0409.jpg', array([125,  35, 240, 150], dtype=int32)], ['image_A0410.jpg', array([139,  97, 325, 283], dtype=int32)], ['image_A0413.jpg', array([ 44,  35, 190, 181], dtype=int32)], ['image_A0418.jpg', array([145,  44, 252, 151], dtype=int32)], ['image_A0419.jpg', array([ 76, 123, 290, 337], dtype=int32)], ['image_A0422.jpg', array([357, 135, 474, 252], dtype=int32)], ['image_A0423.jpg', array([ 60,  35, 198, 173], dtype=int32)], ['image_A0424.jpg', array([ 82, 169, 310, 397], dtype=int32)], ['image_A0425.jpg', array([471, 201, 828, 558], dtype=int32)], ['image_A0426.jpg', array([270, 115, 427, 272], dtype=int32)], ['image_A0427.jpg', array([ 442,  570, 1645, 1773], dtype=int32)], ['image_A0429.jpg', array([1063,  383, 1898, 1218], dtype=int32)], ['image_A0431.jpg', array([250, 154, 327, 241], dtype=int32)], ['image_A0435.jpg', array([134,  40, 248, 154], dtype=int32)], ['image_A0437.jpg', array([ 59, 130, 322, 393], dtype=int32)], ['image_A0440.jpg', array([739, 129, 941, 331], dtype=int32)], ['image_A0441.jpg', array([ 73,  74, 176, 177], dtype=int32)], ['image_A0442.jpg', array([241, 101, 380, 240], dtype=int32)], ['image_A0445.jpg', array([146,  56, 268, 178], dtype=int32)], ['image_A0448.jpg', array([199, 180, 710, 691], dtype=int32)], ['image_A0450.jpg', array([ 64,  46, 177, 159], dtype=int32)], ['image_A0452.jpg', array([268, 325, 540, 606], dtype=int32)], ['image_A0453.jpg', array([ 67,   6, 179, 118], dtype=int32)], ['image_A0454.jpg', array([347,  50, 461, 164], dtype=int32)], ['image_A0455.jpg', array([261, 104, 421, 264], dtype=int32)], ['image_A0457.jpg', array([ 442,  633, 1121, 1312], dtype=int32)], ['image_A0459.jpg', array([370, 184, 653, 648], dtype=int32)], ['image_A0460.jpg', array([297,  62, 815, 580], dtype=int32)], ['image_A0461.jpg', array([168, 113, 484, 429], dtype=int32)], ['image_A0463.jpg', array([143, 224, 519, 600], dtype=int32)], ['image_A0464.jpg', array([ 21,  28, 244, 251], dtype=int32)], ['image_A0465.jpg', array([263, 101, 369, 207], dtype=int32)], ['image_A0467.jpg', array([ 24,  44, 135, 155], dtype=int32)], ['image_A0469.jpg', array([176,  44, 282, 150], dtype=int32)], ['image_A0471.jpg', array([ 78,  84, 288, 294], dtype=int32)], ['image_A0473.jpg', array([189, 271, 707, 789], dtype=int32)], ['image_A0474.jpg', array([484, 117, 717, 350], dtype=int32)], ['image_A0475.jpg', array([218,  88, 352, 222], dtype=int32)], ['image_A0479.jpg', array([188, 117, 415, 344], dtype=int32)], ['image_A0485.jpg', array([132,  91, 348, 411], dtype=int32)], ['image_A0487.jpg', array([ 88, 100, 294, 306], dtype=int32)], ['image_A0488.jpg', array([148,   8, 564, 467], dtype=int32)], ['image_A0490.jpg', array([110,  31, 217, 138], dtype=int32)], ['image_A0491.jpg', array([164,  97, 284, 217], dtype=int32)], ['image_A0494.jpg', array([ 98,  86, 220, 208], dtype=int32)], ['image_A0496.jpg', array([ 48,  40, 163, 155], dtype=int32)], ['image_A0499.jpg', array([142,   4, 379, 241], dtype=int32)], ['image_A0504.jpg', array([ 52,  49, 155, 152], dtype=int32)], ['image_A0505.jpg', array([ 697,  470, 1185,  958], dtype=int32)], ['image_A0506.jpg', array([408, 311, 570, 473], dtype=int32)], ['image_A0509.jpg', array([156, 137, 323, 304], dtype=int32)], ['image_A0515.jpg', array([258,  97, 391, 248], dtype=int32)], ['image_A0517.jpg', array([105, 106, 410, 411], dtype=int32)], ['image_A0518.jpg', array([116,  44, 264, 192], dtype=int32)], ['image_A0519.jpg', array([597, 108, 835, 346], dtype=int32)], ['image_A0520.jpg', array([300,  54, 412, 166], dtype=int32)], ['image_A0521.jpg', array([ 49, 174, 333, 458], dtype=int32)], ['image_A0522.jpg', array([273, 263, 614, 604], dtype=int32)], ['image_A0523.jpg', array([204,  23, 434, 253], dtype=int32)], ['image_A0529.jpg', array([ 82,  67, 197, 182], dtype=int32)], ['image_A0530.jpg', array([139,  56, 256, 173], dtype=int32)], ['image_A0532.jpg', array([162,  95, 375, 308], dtype=int32)], ['image_A0536.jpg', array([102, 150, 296, 344], dtype=int32)], ['image_A0537.jpg', array([221, 235, 579, 593], dtype=int32)], ['image_A0540.jpg', array([294,  74, 320, 107], dtype=int32)], ['image_A0541.jpg', array([429, 226, 641, 438], dtype=int32)], ['image_A0542.jpg', array([245,  52, 358, 165], dtype=int32)], ['image_A0544.jpg', array([ 695,  270, 1050,  625], dtype=int32)], ['image_A0545.jpg', array([ 75,  90, 210, 225], dtype=int32)], ['image_A0547.jpg', array([ 287,  747, 1830, 2290], dtype=int32)], ['image_A0548.jpg', array([137,  91, 260, 214], dtype=int32)], ['image_A0550.jpg', array([480, 161, 797, 478], dtype=int32)], ['image_A0552.jpg', array([177,  79, 287, 189], dtype=int32)], ['image_A0555.jpg', array([137,  97, 382, 342], dtype=int32)], ['image_A0556.jpg', array([ 62,  48, 184, 170], dtype=int32)], ['image_A0557.jpg', array([115,  59, 288, 232], dtype=int32)], ['image_A0558.jpg', array([ 92,  70, 248, 226], dtype=int32)], ['image_A0559.jpg', array([502, 102, 778, 378], dtype=int32)], ['image_A0560.jpg', array([ 84, 104, 285, 305], dtype=int32)], ['image_A0562.jpg', array([ 55,  90, 208, 243], dtype=int32)], ['image_A0564.jpg', array([107,  73, 225, 191], dtype=int32)], ['image_A0566.jpg', array([131,  53, 304, 226], dtype=int32)], ['image_A0569.jpg', array([173,  89, 338, 254], dtype=int32)], ['image_A0570.jpg', array([169, 192, 313, 336], dtype=int32)], ['image_A0573.jpg', array([ 86,  77, 203, 194], dtype=int32)], ['image_A0575.jpg', array([203, 207, 689, 693], dtype=int32)], ['image_A0578.jpg', array([ 44,  92, 240, 288], dtype=int32)], ['image_A0581.jpg', array([ 55,   8, 234, 212], dtype=int32)], ['image_A0584.jpg', array([248, 231, 481, 464], dtype=int32)], ['image_A0585.jpg', array([117,  36, 229, 148], dtype=int32)], ['image_A0586.jpg', array([ 53,  30, 245, 222], dtype=int32)], ['image_A0590.jpg', array([ 56, 140, 355, 439], dtype=int32)], ['image_A0592.jpg', array([ 877,  300, 1171,  594], dtype=int32)], ['image_A0593.jpg', array([ 85,  94, 297, 306], dtype=int32)], ['image_A0594.jpg', array([ 62,  22, 173, 133], dtype=int32)], ['image_A0596.jpg', array([135,  64, 159,  95], dtype=int32)], ['image_A0597.jpg', array([118, 101, 306, 289], dtype=int32)], ['image_A0598.jpg', array([372,  18, 516, 193], dtype=int32)], ['image_A0599.jpg', array([ 85,  68, 218, 201], dtype=int32)], ['image_A0600.jpg', array([ 87, 165, 341, 419], dtype=int32)], ['image_A0609.jpg', array([ 496,  329, 1697, 1530], dtype=int32)], ['image_A0614.jpg', array([ 76,  70, 218, 212], dtype=int32)], ['image_A0616.jpg', array([ 72,  65, 234, 227], dtype=int32)], ['image_A0617.jpg', array([661, 365, 825, 560], dtype=int32)], ['image_A0623.jpg', array([ 83,  65, 220, 202], dtype=int32)], ['image_A0625.jpg', array([ 98,  87, 235, 224], dtype=int32)], ['image_A0635.jpg', array([130,  70, 456, 406], dtype=int32)], ['image_A0636.jpg', array([216,  48, 444, 276], dtype=int32)], ['image_A0638.jpg', array([159,  64, 347, 252], dtype=int32)], ['image_A0640.jpg', array([ 58, 149, 280, 371], dtype=int32)], ['image_A0643.jpg', array([277,  84, 383, 190], dtype=int32)], ['image_A0645.jpg', array([ 64,  19, 177, 132], dtype=int32)], ['image_A0646.jpg', array([ 92,  61, 245, 214], dtype=int32)], ['image_A0647.jpg', array([156, 212, 430, 486], dtype=int32)], ['image_A0648.jpg', array([113,  57, 239, 183], dtype=int32)], ['image_A0649.jpg', array([399, 153, 561, 315], dtype=int32)], ['image_A0650.jpg', array([142,  79, 298, 235], dtype=int32)], ['image_A0651.jpg', array([ 610,  418, 1747, 1555], dtype=int32)], ['image_A0652.jpg', array([ 34,  21, 142, 129], dtype=int32)], ['image_A0653.jpg', array([305, 116, 577, 388], dtype=int32)], ['image_A0655.jpg', array([112,  77, 234, 199], dtype=int32)], ['image_A0658.jpg', array([316, 102, 369, 168], dtype=int32)], ['image_A0660.jpg', array([ 76,  59, 313, 296], dtype=int32)], ['image_A0661.jpg', array([ 79,  86, 223, 230], dtype=int32)], ['image_A0662.jpg', array([ 92, 183, 333, 424], dtype=int32)], ['image_A0665.jpg', array([300, 255, 668, 623], dtype=int32)], ['image_A0666.jpg', array([ 53, 116, 288, 351], dtype=int32)], ['image_A0669.jpg', array([166,  79, 324, 237], dtype=int32)], ['image_A0670.jpg', array([ 816,  375, 1254,  813], dtype=int32)], ['image_A0672.jpg', array([244,  23, 379, 158], dtype=int32)], ['image_A0673.jpg', array([231,  72, 459, 300], dtype=int32)], ['image_A0674.jpg', array([135,  89, 425, 379], dtype=int32)], ['image_A0675.jpg', array([ 90, 152, 285, 347], dtype=int32)], ['image_A0678.jpg', array([ 609,  272, 1032,  695], dtype=int32)], ['image_A0682.jpg', array([227,  86, 346, 205], dtype=int32)], ['image_A0688.jpg', array([261, 147, 505, 442], dtype=int32)], ['image_A0689.jpg', array([261,  71, 383, 193], dtype=int32)], ['image_A0690.jpg', array([133, 274, 579, 927], dtype=int32)], ['image_A0691.jpg', array([120, 119, 319, 318], dtype=int32)], ['image_A0692.jpg', array([126, 111, 292, 277], dtype=int32)], ['image_A0694.jpg', array([233,  40, 376, 183], dtype=int32)], ['image_A0695.jpg', array([188,  75, 294, 181], dtype=int32)], ['image_A0696.jpg', array([154, 203, 661, 710], dtype=int32)], ['image_A0697.jpg', array([ 96,  18, 199, 121], dtype=int32)], ['image_A0699.jpg', array([155, 140, 328, 313], dtype=int32)], ['image_A0703.jpg', array([116, 110, 255, 249], dtype=int32)], ['image_A0704.jpg', array([ 92,  61, 267, 236], dtype=int32)], ['image_A0705.jpg', array([211, 212, 456, 457], dtype=int32)], ['image_A0706.jpg', array([120,  31, 285, 196], dtype=int32)], ['image_A0708.jpg', array([265,  92, 379, 206], dtype=int32)], ['image_A0710.jpg', array([302,  56, 430, 184], dtype=int32)], ['image_A0715.jpg', array([ 35,  16, 141, 122], dtype=int32)], ['image_A0716.jpg', array([426, 184, 709, 467], dtype=int32)], ['image_A0717.jpg', array([158,  24, 277, 143], dtype=int32)], ['image_A0720.jpg', array([ 71,  88, 223, 240], dtype=int32)], ['image_A0721.jpg', array([ 428,  933, 1332, 1837], dtype=int32)], ['image_A0722.jpg', array([139, 122, 394, 377], dtype=int32)], ['image_A0723.jpg', array([ 46,  78, 193, 225], dtype=int32)], ['image_A0724.jpg', array([490, 173, 540, 244], dtype=int32)], ['image_A0725.jpg', array([124, 159, 434, 469], dtype=int32)], ['image_A0726.jpg', array([ 302,  280, 1059, 1037], dtype=int32)], ['image_A0727.jpg', array([403, 161, 545, 303], dtype=int32)], ['image_A0730.jpg', array([151, 154, 500, 503], dtype=int32)], ['image_A0732.jpg', array([110,  18, 225, 133], dtype=int32)], ['image_A0736.jpg', array([269, 148, 483, 362], dtype=int32)], ['image_A0738.jpg', array([130,  73, 233, 176], dtype=int32)], ['image_A0739.jpg', array([190,  56, 525, 391], dtype=int32)], ['image_A0740.jpg', array([ 46,  92, 163, 209], dtype=int32)], ['image_A0742.jpg', array([ 74,  18, 177, 121], dtype=int32)], ['image_A0743.jpg', array([491, 209, 935, 653], dtype=int32)], ['image_A0744.jpg', array([ 71, 126, 291, 346], dtype=int32)], ['image_A0745.jpg', array([ 57,  67, 209, 219], dtype=int32)], ['image_A0746.jpg', array([ 16,  96, 166, 246], dtype=int32)], ['image_A0748.jpg', array([217, 116, 450, 349], dtype=int32)], ['image_A0749.jpg', array([ 72,  70, 258, 256], dtype=int32)], ['image_A0750.jpg', array([132, 121, 372, 361], dtype=int32)], ['image_A0751.jpg', array([219,  67, 375, 223], dtype=int32)], ['image_A0752.jpg', array([ 91, 109, 272, 290], dtype=int32)], ['image_A0754.jpg', array([288, 192, 654, 558], dtype=int32)], ['image_A0755.jpg', array([ 45,  51, 173, 179], dtype=int32)], ['image_A0756.jpg', array([147, 112, 286, 325], dtype=int32)], ['image_A0757.jpg', array([166,  39, 280, 153], dtype=int32)], ['image_A0758.jpg', array([100,  39, 206, 145], dtype=int32)], ['image_A0759.jpg', array([163, 119, 279, 235], dtype=int32)], ['image_A0762.jpg', array([468, 114, 786, 432], dtype=int32)], ['image_A0763.jpg', array([240, 120, 453, 404], dtype=int32)], ['image_A0767.jpg', array([ 706,  631, 1068,  993], dtype=int32)], ['image_A0769.jpg', array([248, 158, 465, 375], dtype=int32)], ['image_A0770.jpg', array([ 83,  94, 302, 313], dtype=int32)], ['image_A0772.jpg', array([136, 123, 353, 340], dtype=int32)], ['image_A0773.jpg', array([174, 133, 321, 280], dtype=int32)], ['image_A0780.jpg', array([234,  17, 393, 176], dtype=int32)], ['image_A0783.jpg', array([122,  18, 244, 140], dtype=int32)], ['image_A0784.jpg', array([ 62,  46, 207, 191], dtype=int32)], ['image_A0786.jpg', array([178, 177, 652, 651], dtype=int32)], ['image_A0789.jpg', array([ 60, 102, 159, 223], dtype=int32)], ['image_A0790.jpg', array([129, 152, 412, 435], dtype=int32)], ['image_A0792.jpg', array([281, 127, 540, 386], dtype=int32)], ['image_A0796.jpg', array([362, 346, 890, 874], dtype=int32)], ['image_A0797.jpg', array([ 47,  30, 606, 589], dtype=int32)], ['image_A0798.jpg', array([ 61,  59, 200, 198], dtype=int32)], ['image_A0802.jpg', array([341,  41, 604, 304], dtype=int32)], ['image_A0804.jpg', array([ 90,  65, 305, 280], dtype=int32)], ['image_A0805.jpg', array([ 62,  85, 178, 201], dtype=int32)], ['image_A0807.jpg', array([468, 195, 580, 307], dtype=int32)], ['image_A0812.jpg', array([139,  18, 334, 213], dtype=int32)], ['image_A0816.jpg', array([291,  66, 453, 228], dtype=int32)], ['image_A0817.jpg', array([327, 181, 624, 478], dtype=int32)], ['image_A0818.jpg', array([150,  66, 271, 187], dtype=int32)], ['image_A0822.jpg', array([ 56, 166, 345, 455], dtype=int32)], ['image_A0823.jpg', array([ 89,  29, 202, 142], dtype=int32)], ['image_A0824.jpg', array([118,  77, 239, 198], dtype=int32)], ['image_A0826.jpg', array([ 680,  530, 1262, 1112], dtype=int32)], ['image_A0827.jpg', array([ 62,  85, 190, 213], dtype=int32)], ['image_A0829.jpg', array([200, 148, 486, 434], dtype=int32)], ['image_A0831.jpg', array([ 24,  62, 141, 179], dtype=int32)], ['image_A0832.jpg', array([ 54,  86, 186, 218], dtype=int32)], ['image_A0834.jpg', array([ 96,  81, 288, 273], dtype=int32)], ['image_A0835.jpg', array([170,  72, 349, 263], dtype=int32)], ['image_A0836.jpg', array([260, 105, 475, 320], dtype=int32)], ['image_A0838.jpg', array([524, 327, 706, 509], dtype=int32)], ['image_A0839.jpg', array([ 76,  50, 238, 212], dtype=int32)], ['image_A0840.jpg', array([ 450,  486, 1250, 1286], dtype=int32)], ['image_A0841.jpg', array([127,  61, 327, 261], dtype=int32)], ['image_A0843.jpg', array([264,  71, 367, 174], dtype=int32)], ['image_A0846.jpg', array([ 42, 208, 430, 596], dtype=int32)], ['image_A0849.jpg', array([ 71, 106, 160, 238], dtype=int32)], ['image_A0851.jpg', array([242,  38, 366, 162], dtype=int32)], ['image_A0853.jpg', array([190, 103, 336, 249], dtype=int32)], ['image_A0854.jpg', array([ 20,  39, 128, 147], dtype=int32)], ['image_A0856.jpg', array([236,  70, 355, 189], dtype=int32)], ['image_A0858.jpg', array([106, 111, 294, 299], dtype=int32)], ['image_A0859.jpg', array([ 89,  22, 238, 171], dtype=int32)], ['image_A0860.jpg', array([274, 270, 619, 615], dtype=int32)], ['image_A0862.jpg', array([290, 207, 678, 595], dtype=int32)], ['image_A0863.jpg', array([ 24,  59, 255, 290], dtype=int32)], ['image_A0865.jpg', array([102,  29, 175, 113], dtype=int32)], ['image_A0866.jpg', array([122, 147, 366, 391], dtype=int32)], ['image_A0869.jpg', array([ 99, 228, 409, 538], dtype=int32)], ['image_A0870.jpg', array([ 87,  92, 234, 239], dtype=int32)], ['image_A0871.jpg', array([132, 147, 374, 389], dtype=int32)], ['image_A0872.jpg', array([109,  82, 285, 258], dtype=int32)], ['image_A0873.jpg', array([177, 175, 443, 441], dtype=int32)], ['image_A0877.jpg', array([ 39,  59, 186, 206], dtype=int32)], ['image_A0879.jpg', array([ 72,  78, 260, 266], dtype=int32)], ['image_A0880.jpg', array([ 98,  39, 218, 159], dtype=int32)], ['image_A0881.jpg', array([ 423,  447, 1280, 1304], dtype=int32)], ['image_A0882.jpg', array([265, 239, 702, 676], dtype=int32)], ['image_A0883.jpg', array([179,  63, 411, 295], dtype=int32)], ['image_A0884.jpg', array([ 57,  48, 174, 165], dtype=int32)], ['image_A0885.jpg', array([244, 129, 449, 387], dtype=int32)], ['image_A0886.jpg', array([149, 113, 377, 341], dtype=int32)], ['image_A0887.jpg', array([ 573,  120, 1311,  858], dtype=int32)], ['image_A0888.jpg', array([ 71,  65, 221, 238], dtype=int32)], ['image_A0892.jpg', array([195, 118, 365, 288], dtype=int32)], ['image_A0893.jpg', array([ 492,  375, 1264, 1147], dtype=int32)], ['image_A0894.jpg', array([ 45, 112, 375, 442], dtype=int32)], ['image_A0898.jpg', array([ 66, 125, 265, 324], dtype=int32)], ['image_A0899.jpg', array([124,  57, 231, 164], dtype=int32)], ['image_A0902.jpg', array([201, 177, 514, 490], dtype=int32)], ['image_A0903.jpg', array([341, 148, 517, 324], dtype=int32)], ['image_A0904.jpg', array([186,  56, 294, 164], dtype=int32)], ['image_A0905.jpg', array([316, 122, 450, 256], dtype=int32)], ['image_A0907.jpg', array([ 66, 114, 313, 361], dtype=int32)], ['image_A0909.jpg', array([124, 148, 347, 371], dtype=int32)], ['image_A0911.jpg', array([207, 246, 710, 749], dtype=int32)], ['image_A0912.jpg', array([292, 230, 696, 634], dtype=int32)], ['image_A0913.jpg', array([ 63,  35, 233, 205], dtype=int32)], ['image_A0916.jpg', array([ 926,  430, 1508, 1012], dtype=int32)], ['image_A0918.jpg', array([ 864,  245, 1200,  581], dtype=int32)], ['image_A0922.jpg', array([231,  62, 362, 193], dtype=int32)], ['image_A0923.jpg', array([ 63,  98, 265, 300], dtype=int32)], ['image_A0924.jpg', array([145,  82, 281, 218], dtype=int32)], ['image_A0925.jpg', array([400, 172, 624, 396], dtype=int32)], ['image_A0926.jpg', array([ 393,  652, 1273, 1532], dtype=int32)], ['image_A0929.jpg', array([ 89,  88, 173, 179], dtype=int32)], ['image_A0930.jpg', array([ 21,  82, 153, 214], dtype=int32)], ['image_A0931.jpg', array([ 51, 105, 267, 321], dtype=int32)], ['image_A0932.jpg', array([ 96,  86, 234, 224], dtype=int32)], ['image_A0933.jpg', array([177,  51, 280, 154], dtype=int32)], ['image_A0934.jpg', array([161, 116, 356, 311], dtype=int32)], ['image_A0938.jpg', array([ 50,  47, 168, 178], dtype=int32)], ['image_A0939.jpg', array([ 49,  41, 161, 153], dtype=int32)], ['image_A0944.jpg', array([100,  52, 162, 130], dtype=int32)], ['image_A0946.jpg', array([149,   8, 252, 111], dtype=int32)], ['image_A0947.jpg', array([112,  85, 215, 188], dtype=int32)], ['image_A0948.jpg', array([235, 226, 661, 652], dtype=int32)], ['image_A0950.jpg', array([227, 313, 599, 685], dtype=int32)], ['image_A0951.jpg', array([ 68,  58, 189, 179], dtype=int32)], ['image_A0954.jpg', array([200, 134, 346, 305], dtype=int32)], ['image_A0956.jpg', array([ 70, 114, 194, 238], dtype=int32)], ['image_A0960.jpg', array([ 80,  67, 202, 189], dtype=int32)], ['image_A0963.jpg', array([ 55,  90, 258, 293], dtype=int32)], ['image_A0964.jpg', array([179, 306, 261, 369], dtype=int32)], ['image_A0965.jpg', array([172,  49, 289, 166], dtype=int32)], ['image_A0967.jpg', array([317, 204, 694, 581], dtype=int32)], ['image_A0968.jpg', array([213, 131, 431, 349], dtype=int32)], ['image_A0969.jpg', array([ 28,  58, 164, 194], dtype=int32)], ['image_A0970.jpg', array([ 81,  70, 235, 224], dtype=int32)], ['image_A0971.jpg', array([ 57,  66, 182, 191], dtype=int32)], ['image_A0975.jpg', array([ 78,  41, 213, 176], dtype=int32)], ['image_A0979.jpg', array([258, 238, 681, 661], dtype=int32)], ['image_A0980.jpg', array([208,  35, 338, 165], dtype=int32)], ['image_A0982.jpg', array([180, 293, 566, 679], dtype=int32)], ['image_A0983.jpg', array([168, 180, 414, 464], dtype=int32)], ['image_A0988.jpg', array([236,  91, 378, 291], dtype=int32)], ['image_A0989.jpg', array([ 73,  64, 197, 188], dtype=int32)], ['image_A0991.jpg', array([199,  18, 388, 207], dtype=int32)], ['image_A0995.jpg', array([224, 119, 362, 278], dtype=int32)], ['image_A0998.jpg', array([284,  11, 498, 225], dtype=int32)], ['image_A0999.jpg', array([ 85, 121, 261, 297], dtype=int32)], ['image_A1002.jpg', array([ 68,  55, 182, 169], dtype=int32)], ['image_A1004.jpg', array([103,  14, 277, 188], dtype=int32)], ['image_A1007.jpg', array([189, 122, 404, 337], dtype=int32)], ['image_A1008.jpg', array([114,  90, 265, 266], dtype=int32)], ['image_A1009.jpg', array([ 62,  61, 249, 243], dtype=int32)], ['image_A1010.jpg', array([315, 132, 511, 328], dtype=int32)], ['image_A1011.jpg', array([486, 267, 748, 529], dtype=int32)], ['image_A1013.jpg', array([238,  29, 341, 132], dtype=int32)], ['image_A1017.jpg', array([191, 115, 400, 391], dtype=int32)], ['image_A1019.jpg', array([105,  68, 253, 262], dtype=int32)], ['image_A1021.jpg', array([170,  66, 320, 216], dtype=int32)], ['image_A1022.jpg', array([162,  52, 319, 209], dtype=int32)], ['image_A1023.jpg', array([139, 112, 344, 317], dtype=int32)], ['image_A1025.jpg', array([ 91,  94, 217, 220], dtype=int32)], ['image_A1026.jpg', array([170,  71, 514, 380], dtype=int32)], ['image_A1028.jpg', array([157, 128, 342, 313], dtype=int32)], ['image_A1030.jpg', array([ 27,  14, 193, 180], dtype=int32)], ['image_A1032.jpg', array([235,  54, 349, 168], dtype=int32)], ['image_A1037.jpg', array([104,  84, 213, 193], dtype=int32)], ['image_A1041.jpg', array([149,  31, 292, 174], dtype=int32)], ['image_A1042.jpg', array([212,  82, 376, 246], dtype=int32)], ['image_A1043.jpg', array([ 54,  49, 177, 172], dtype=int32)], ['image_A1044.jpg', array([163, 171, 464, 472], dtype=int32)], ['image_A1047.jpg', array([128,  88, 272, 232], dtype=int32)], ['image_A1049.jpg', array([692, 315, 853, 476], dtype=int32)], ['image_A1052.jpg', array([214, 119, 379, 284], dtype=int32)], ['image_A1054.jpg', array([104, 119, 300, 315], dtype=int32)], ['image_A1061.jpg', array([235, 185, 412, 362], dtype=int32)], ['image_A1062.jpg', array([123, 132, 334, 343], dtype=int32)], ['image_A1063.jpg', array([ 64,  78, 216, 230], dtype=int32)], ['image_A1064.jpg', array([ 34,  42, 144, 152], dtype=int32)], ['image_A1065.jpg', array([327, 171, 537, 381], dtype=int32)], ['image_A1068.jpg', array([142, 207, 559, 624], dtype=int32)], ['image_A1069.jpg', array([ 62,  24, 165, 127], dtype=int32)], ['image_A1075.jpg', array([100, 133, 269, 334], dtype=int32)], ['image_A1077.jpg', array([ 64,  91, 203, 230], dtype=int32)], ['image_A1078.jpg', array([260, 110, 452, 302], dtype=int32)], ['image_A1081.jpg', array([112,  90, 219, 197], dtype=int32)], ['image_A1087.jpg', array([551, 122, 621, 203], dtype=int32)], ['image_A1088.jpg', array([212,  72, 331, 191], dtype=int32)], ['image_A1091.jpg', array([392, 103, 590, 301], dtype=int32)], ['image_A1093.jpg', array([198,  38, 301, 141], dtype=int32)], ['image_A1095.jpg', array([ 91,  59, 262, 238], dtype=int32)], ['image_A1096.jpg', array([641, 180, 965, 504], dtype=int32)], ['image_A1097.jpg', array([ 29,  59, 240, 270], dtype=int32)], ['image_A1098.jpg', array([182,  34, 435, 287], dtype=int32)], ['image_A1099.jpg', array([618, 128, 966, 476], dtype=int32)], ['image_A1103.jpg', array([115, 131, 338, 354], dtype=int32)], ['image_A1107.jpg', array([ 35,  83, 255, 303], dtype=int32)], ['image_A1108.jpg', array([360, 115, 600, 355], dtype=int32)], ['image_A1111.jpg', array([215, 107, 377, 269], dtype=int32)], ['image_A1112.jpg', array([ 92,  80, 271, 259], dtype=int32)], ['image_A1114.jpg', array([100,  51, 210, 161], dtype=int32)], ['image_A1116.jpg', array([187, 168, 505, 486], dtype=int32)], ['image_A1117.jpg', array([127,  45, 257, 175], dtype=int32)], ['image_A1121.jpg', array([ 73, 100, 275, 302], dtype=int32)], ['image_A1122.jpg', array([506, 166, 657, 317], dtype=int32)], ['image_A1123.jpg', array([ 95,  68, 278, 251], dtype=int32)], ['image_A1124.jpg', array([176,  97, 335, 256], dtype=int32)], ['image_A1125.jpg', array([509,  85, 622, 198], dtype=int32)], ['image_A1127.jpg', array([416, 280, 867, 731], dtype=int32)], ['image_A1128.jpg', array([136,  76, 327, 267], dtype=int32)], ['image_A1131.jpg', array([ 74,  76, 257, 259], dtype=int32)], ['image_A1132.jpg', array([262,  73, 368, 179], dtype=int32)], ['image_A1133.jpg', array([283, 289, 729, 735], dtype=int32)], ['image_A1134.jpg', array([144,  58, 256, 170], dtype=int32)], ['image_A1135.jpg', array([106,  32, 213, 167], dtype=int32)], ['image_A1138.jpg', array([122,  88, 225, 191], dtype=int32)], ['image_A1139.jpg', array([162, 152, 347, 337], dtype=int32)], ['image_A1140.jpg', array([106,  19, 209, 122], dtype=int32)], ['image_A1141.jpg', array([262,  31, 333,  97], dtype=int32)], ['image_A1142.jpg', array([ 38,  43, 144, 149], dtype=int32)], ['image_A1145.jpg', array([136,  62, 317, 243], dtype=int32)], ['image_A1147.jpg', array([ 592,  381, 1127,  916], dtype=int32)], ['image_A1148.jpg', array([184,  86, 350, 252], dtype=int32)], ['image_A1153.jpg', array([292,  85, 406, 199], dtype=int32)], ['image_A1155.jpg', array([ 97,  90, 292, 285], dtype=int32)], ['image_A1159.jpg', array([ 89,  50, 203, 164], dtype=int32)], ['image_A1162.jpg', array([125, 196, 420, 491], dtype=int32)], ['image_A1166.jpg', array([179, 103, 335, 259], dtype=int32)], ['image_A1168.jpg', array([ 32,  48, 139, 155], dtype=int32)], ['image_A1170.jpg', array([241, 117, 501, 377], dtype=int32)], ['image_A1171.jpg', array([ 84,  86, 241, 243], dtype=int32)], ['image_A1174.jpg', array([327, 266, 592, 531], dtype=int32)], ['image_A1178.jpg', array([161, 120, 352, 311], dtype=int32)], ['image_A1179.jpg', array([205,  92, 413, 300], dtype=int32)], ['image_A1181.jpg', array([268,  70, 382, 184], dtype=int32)], ['image_A1182.jpg', array([ 55,  99, 207, 251], dtype=int32)], ['image_A1187.jpg', array([163,  53, 255, 182], dtype=int32)], ['image_A1188.jpg', array([ 737,  409, 1131,  803], dtype=int32)], ['image_A1189.jpg', array([245, 165, 355, 275], dtype=int32)], ['image_A1190.jpg', array([ 28,  39, 138, 149], dtype=int32)], ['image_A1193.jpg', array([171, 106, 270, 228], dtype=int32)], ['image_A1195.jpg', array([237, 170, 584, 517], dtype=int32)], ['image_A1197.jpg', array([361, 312, 753, 704], dtype=int32)], ['image_A1199.jpg', array([130,  57, 252, 179], dtype=int32)]]\n"
     ]
    }
   ],
   "source": [
    "# transforms son copiados, revisar\n",
    "# calcular valores de mean y std del dataset para cada channel\n",
    "# o las de imagenet\n",
    "# flipping, cambios de colores, grayscale\n",
    "# contraste de saturacion \n",
    "# color spaces\n",
    "################\n",
    "\n",
    "all_data = load_data('AGC_Challenge3_Training.mat')\n",
    "print(all_data)\n",
    "train_data, val_data, test_data = random_split(all_data, [0.8, 0.1, 0.1], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# train_mean, train_std = compute_mean_std(train_data)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize(300, 300),\n",
    "    transforms.RandomResizedCrop(resized),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=train_mean, std=train_std)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_base = transforms.Compose([\n",
    "    transforms.Resize(resized),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = MyData(train_data, transform)\n",
    "val_dataset = MyData(val_data, transform)\n",
    "test_dataset = MyData(test_data, transform)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionCNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(41472, 128), # 128*8*8 or 128*3*4\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.cnn_layers(data)\n",
    "        x = self.flatten(x) # before linear layer !!!\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "    def fit(self, training_data, loss_fn, optimizer: optim.Optimizer): # cross entropy con softmax + adam\n",
    "        self.train()\n",
    "        for e in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for batch_idx, (batch_data, target) in enumerate(training_data):\n",
    "                optimizer.zero_grad()\n",
    "                output = self.forward(batch_data)\n",
    "                loss = loss_fn(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            if e % epoch_step == 0:\n",
    "                print(f'Epoch {e} has loss {epoch_loss / batch_size}')\n",
    "\n",
    "    def evaluate(self, validation_data, loss_fn): # unused by now\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        for images, labels in validation_data:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            output = self.forward(images)\n",
    "            loss = loss_fn(output, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        average_loss = total_loss / len(validation_data)\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "\n",
    "        return average_loss, accuracy\n",
    "\n",
    "    def predict(self, test_image):\n",
    "        self.eval()\n",
    "        with torch.inference_mode(mode=True):\n",
    "            test_image = test_image.convert('RGB')\n",
    "            w, h = get_image_size(test_image)\n",
    "            test_image = transform_base(test_image)\n",
    "            test_image = torch.tensor(test_image, dtype=torch.float32)\n",
    "            output = self.forward(test_image.unsqueeze(0))[0]\n",
    "            print(output)\n",
    "            output = [output[0]*w/resized[0], output[1]*h/resized[1], output[2]*w/resized[0], output[3]*h/resized[1]]\n",
    "            print(output)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DetectionCNNModel(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Linear(in_features=41472, out_features=128, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=128, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "detection = DetectionCNNModel().to(device)\n",
    "print(detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5406980\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in detection.parameters())\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11454/1679506722.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  image = torch.tensor(image, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 has loss 2317.8086376190186\n",
      "Epoch 10 has loss 331.1100444793701\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[327], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(detection\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mdetection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[324], line 45\u001b[0m, in \u001b[0;36mDetectionCNNModel.fit\u001b[0;34m(self, training_data, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (batch_data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(training_data):\n\u001b[1;32m     44\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 45\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(output, target)\n\u001b[1;32m     47\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[324], line 34\u001b[0m, in \u001b[0;36mDetectionCNNModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m---> 34\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x) \u001b[38;5;66;03m# before linear layer !!!\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_layers(x)\n",
      "File \u001b[0;32m~/Documents/repos/AGiC-2024/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/repos/AGiC-2024/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/repos/AGiC-2024/.venv/lib64/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/repos/AGiC-2024/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/repos/AGiC-2024/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/repos/AGiC-2024/.venv/lib64/python3.12/site-packages/torch/nn/modules/batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/repos/AGiC-2024/.venv/lib64/python3.12/site-packages/torch/nn/functional.py:2482\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2480\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2482\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2483\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2484\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train loop as train and then test\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(detection.parameters(), lr=lr)\n",
    "\n",
    "detection.fit(train_loader, loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(detection, 'detection_model.pth') # not model.state_dict() because we want to store the class also\n",
    "\n",
    "detection_scripted = torch.jit.script(detection)\n",
    "detection_scripted.save('detection_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9339, -1.3720,  0.1093, -0.0579])\n",
      "[tensor(-1.9424), tensor(-1.5137), tensor(0.2274), tensor(-0.0639)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11454/4216303844.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_image = torch.tensor(test_image, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "with Image.open(images_path + 'image_A0003.jpg') as image:\n",
    "    detection.predict(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecognitionCNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "# 2 linear layers\n",
    "# va a sacar un vector y hacer argmax\n",
    "# multimodal ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecognitionCNNModel().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'recognition_model.pth') # not model.state_dict() because we want to store the class also"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
