{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Session 3: Facial Expressions and Emotion Perception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors:\n",
    "\n",
    "    - Luca Franceschi (u199149)\n",
    "    - Telmo Linacisoro (u198711)\n",
    "\n",
    "# Facial Expressions and Emotion Perception\n",
    "In this notebook we analyze how different are radom annotations from the ones we got as a result of comparing images by similarity to prove that human made annotations provide some genuine insight. We will extract principal components using MDS and reconstruct the circumplex model of affect from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToSimScores = './simScores.mat'\n",
    "pathToImages = 'group_2/'\n",
    "\n",
    "size = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_names(path):\n",
    "    names_raw = os.listdir(path)\n",
    "    return [name.split('.')[0] for name in names_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_similarity_scores(path):\n",
    "    simScores = scipy.io.loadmat(path)['simScores'][0][0]\n",
    "    return np.array(simScores[0]), np.array(simScores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_matrix(matrix, title='Matrix', labels=None):\n",
    "    plt.imshow(matrix)\n",
    "    if labels != None:\n",
    "        plt.xticks(range(len(labels)), labels, rotation=90)\n",
    "        plt.yticks(range(len(labels)), labels)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_similarity_consistency_matrices(simMat, consMat, labels):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 10))\n",
    "    axs = axs.flatten()\n",
    "    axs[0].imshow(simMat)\n",
    "    axs[0].set_title('Similarity Matrix')\n",
    "    axs[0].set_xticks(range(len(labels)), labels, rotation=90)\n",
    "    axs[0].set_yticks(range(len(labels)), labels)\n",
    "    im = axs[1].imshow(consMat)\n",
    "    axs[1].set_title('Consistency Matrix')\n",
    "    axs[1].set_xticks(range(len(labels)), labels, rotation=90)\n",
    "    axs[1].set_yticks([])\n",
    "    \n",
    "\n",
    "    cax = fig.add_axes([1, 0.285, 0.03, 0.43])\n",
    "    plt.colorbar(im, cax=cax)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simMat, consMat = load_similarity_scores(pathToSimScores)\n",
    "\n",
    "image_names = load_image_names(pathToImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_similarity_consistency_matrices(simMat, consMat, image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_matrix(size, e=20):\n",
    "    epoch = 0\n",
    "    mat = np.zeros((size, size))\n",
    "    while (epoch < e):\n",
    "        mat += np.random.random(size=(size, size))\n",
    "        epoch += 1\n",
    "    return mat / e * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dissimilarity(simMat, size=size):\n",
    "    dissimilarity = np.zeros(shape=(size, size))\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            dissimilarity[i][j] = np.sqrt(abs(simMat[i][i] - 2 * simMat[i][j] + simMat[i][i])) # abs is there because errors in the random similarity matrix (many negatives)\n",
    "\n",
    "    return dissimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dissMat = get_dissimilarity(simMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_matrix(dissMat, 'Dissimilarity Matrix', image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(matrix, num_components: int = 10):\n",
    "    covariance_matrix = np.cov(matrix, rowvar=False) # The variables are columns, the observations are rows (default is reversed)\n",
    "\n",
    "    # Compute eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "\n",
    "    # Sort best components (higher eigenvalue means more variance explained in that eigenvector than in others)\n",
    "    idx = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    eigenvectors = eigenvectors[:, idx]\n",
    "\n",
    "    # Take the first num_components from the spectral decomposition\n",
    "    eigenvectors = eigenvectors[:, :num_components]\n",
    "\n",
    "    return eigenvalues, eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mds(dissMat, size=size):\n",
    "\n",
    "    # 1. Compute matrix A from dissimilarity matrix, where a[i][j] = -(1/2)dissMat^2\n",
    "    A = - dissMat**2 / 2\n",
    "\n",
    "    # 2. Compute the \"doubly centered\" matrix B = HAH\n",
    "    H = np.identity(size) - (1 / size) * np.ones(shape=(size, size))\n",
    "    \n",
    "    B = H * A * H\n",
    "\n",
    "    eigval, eigvec = pca(B, 2)\n",
    "\n",
    "    if (eigval[0] < 0 or eigval[1] < 0):\n",
    "        print(eigval)\n",
    "        return -1\n",
    "\n",
    "    projection = np.dot(B, eigvec)\n",
    "\n",
    "    return eigval[0:2], eigvec, projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors, projection = mds(dissMat)\n",
    "print(eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hide_bounding_box(ax):\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.spines['bottom'].set_color('white')\n",
    "    ax.spines['top'].set_color('white') \n",
    "    ax.spines['right'].set_color('white')\n",
    "    ax.spines['left'].set_color('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_axis(ax):\n",
    "    hide_bounding_box(ax)\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "    unit_circle = plt.Circle((0, 0), 1, fill=False)\n",
    "    x = patches.FancyArrowPatch((0, -1.1), (0, 1.1), arrowstyle='->', mutation_scale=20)\n",
    "    y = patches.FancyArrowPatch((-1.1, 0), (1.1, 0), arrowstyle='->', mutation_scale=20)\n",
    "\n",
    "    ax.add_patch(x)\n",
    "    ax.add_patch(y)\n",
    "    ax.add_patch(unit_circle)\n",
    "\n",
    "    plt.annotate(text='Arousal', xy=(0, 1.1))\n",
    "    plt.annotate(text='Valence', xy=(1.1, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colormap(labels):\n",
    "    colormap = []\n",
    "    for label in labels:\n",
    "        emotion = label.split('_')[0]\n",
    "        if emotion == 'happiness':\n",
    "            colormap.append('forestgreen')\n",
    "        elif emotion == 'laughter':\n",
    "            colormap.append('lime')\n",
    "        elif emotion == 'friendly':\n",
    "            colormap.append('gold')\n",
    "        elif emotion == 'surprised':\n",
    "            colormap.append('magenta')\n",
    "        elif emotion == 'boredom':\n",
    "            colormap.append('thistle')\n",
    "        elif emotion == 'disgusted':\n",
    "            colormap.append('tan')\n",
    "        elif emotion == 'sadness':\n",
    "            colormap.append('steelblue')\n",
    "        elif emotion == 'angry':\n",
    "            colormap.append('tomato')\n",
    "    return colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cma(proj, labels, title=None):\n",
    "    fig, axs = plt.subplots(figsize=(8, 8))\n",
    "    \n",
    "    show_axis(axs)\n",
    "\n",
    "    # Normalize, otherwise too bad\n",
    "    points = np.zeros(shape=(proj.shape))\n",
    "    points[:, 0] = (proj[:, 0]-min(proj[:, 0])) / (max(proj[:, 0])-min(proj[:, 0])) * 2 - 1\n",
    "    points[:, 1] = (proj[:, 1]-min(proj[:, 1])) / (max(proj[:, 1])-min(proj[:, 1])) * 2 - 1\n",
    "\n",
    "    points[:, 0] = -points[:, 0] # flip valence axis\n",
    "    # points = proj\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        plt.annotate(text=label, xy=(points[i, 0]-0.1*np.sign(points[i, 0]), points[i, 1]+0.04*np.sign(points[i, 1])), fontsize=8, ha='center')\n",
    "\n",
    "    colors = get_colormap(labels)\n",
    "\n",
    "    plt.scatter(points[:, 0], points[:, 1], c=colors)\n",
    "\n",
    "    plt.title('Circumplex Model of Affect: ' + title)\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cma(projection, image_names, 'Our results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_matrix = generate_random_matrix(size, e=20)\n",
    "display_matrix(random_matrix, 'Random matrix similarity', image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dissMatRandom = get_dissimilarity(random_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues_rand, eigenvectors_rand, projection_rand = mds(dissMatRandom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cma(projection_rand, image_names, 'Random similarity matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the accuracy we will generate the perfect similarity matrix and the compare it to ours and the random generated one Using MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfectSimm = np.zeros(shape=(size, size))\n",
    "\n",
    "for i in range(0, size, 3):\n",
    "    for j in range(0, 3):\n",
    "        for k in range(0, 3):\n",
    "            perfectSimm[i+j][i+k] = 9\n",
    "\n",
    "display_matrix(perfectSimm, 'Perfect Simmilarity matrix', image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(A, B):\n",
    "    return ((A - B)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(perfectSimm, simMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(perfectSimm, random_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(simMat, random_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worstSimm = get_dissimilarity(perfectSimm)\n",
    "worstSimm = worstSimm / worstSimm.max() * 9\n",
    "display_matrix(worstSimm, 'Worst simmilarity matrix', image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(perfectSimm, worstSimm) # the worst you can get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the perfect CMA look (just hanging around)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_eigenvalues, p_eigenvectors, p_proj = mds(get_dissimilarity(perfectSimm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cma(p_proj, image_names, 'The best we can get (bad?)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
